This is a code release of captioning videos using Neuraltalk2. We provide a way to extract the deep image feature of VGG-16, and detect shot boundaries using the feature. We annotate the key frames, and return the captions to the video sequence. A sample output can be found at https://youtu.be/FmSsek5luHk. 

Required libraries:
- Caffe: https://github.com/BVLC/caffe
- neuraltalk2: https://github.com/karpathy/neuraltalk2
- ffmpeg: https://www.ffmpeg.org/

Guanqun CAO
09/01/2016
